import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
from pathlib import Path
import glob
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import platform
from llama_stack.llama import Llama

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="Job-Fit Insight Dashboard with AI",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. CSS ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .main-header { background: linear-gradient(90deg, #1f4e79 0%, #2980b9 100%); padding: 1.5rem; border-radius: 10px; color: white; margin-bottom: 2rem; }
    .highlight-card { background: white; padding: 1.5rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); border-left: 5px solid #ff6b35; }
    .job-posting-card { background: #ffffff; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 1rem; border: 1px solid #e9ecef; }
    .job-posting-card a { text-decoration: none; color: #1f4e79; font-weight: bold; font-size: 1.1em; }
    .job-posting-card p { margin: 0.3rem 0; color: #495057; font-size: 0.9em; }
    div[data-testid="metric-container"] { background-color: #f8f9fa; border-left: 5px solid #2980b9; padding: 1rem; border-radius: 10px; }
</style>
""", unsafe_allow_html=True)


# --- 3. ë°ì´í„° ë¡œë”© ë° ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_resource
def init_connection(db_path="data/job_fit_insight.db"):
    db_file = Path(db_path)
    if not db_file.exists():
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼('{db_path}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `setup_database.py`ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        st.stop()
    return sqlite3.connect(db_file, check_same_thread=False)

def generate_sample_youth_data():
    data = {'ì„±ë³„': ['ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨ì„±', 'ì—¬ì„±'], 'ì—°ë ¹ê³„ì¸µë³„': ['15-29ì„¸', '15-29ì„¸', '30-39ì„¸', '30-39ì„¸'], '2025.03_ì‹¤ì—…ë¥ ': [6.8, 6.1, 3.1, 3.5], '2025.03_ê²½ì œí™œë™ì¸êµ¬': [2450000, 2150000, 3400000, 3100000], '2025.03_ì·¨ì—…ì': [2283000, 2018000, 3295000, 2990000], '2025.04_ì‹¤ì—…ë¥ ': [7.0, 6.3, 3.2, 3.6], '2025.04_ê²½ì œí™œë™ì¸êµ¬': [2460000, 2160000, 3420000, 3120000], '2025.04_ì·¨ì—…ì': [2287000, 2023000, 3310000, 3010000], '2025.05_ì‹¤ì—…ë¥ ': [6.9, 6.2, 3.0, 3.4], '2025.05_ê²½ì œí™œë™ì¸êµ¬': [2470000, 2170000, 3430000, 3130000], '2025.05_ì·¨ì—…ì': [2299000, 2035000, 3325000, 3020000]}
    return pd.DataFrame(data)

@st.cache_data
def load_all_data(_conn):
    skills_df = pd.read_sql("SELECT * FROM top10_skills_per_job", _conn)
    levels_df = pd.read_sql("SELECT * FROM joblevel_counts", _conn)
    rallit_df = None
    try:
        csv_files = glob.glob(str(Path("data") / "rallit_*.csv"))
        if csv_files: rallit_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True).drop_duplicates(subset=['url']).reset_index(drop=True)
    except Exception as e: print(f"Error loading Rallit CSVs: {e}")
    try: youth_df = pd.read_sql("SELECT * FROM youth_summary", _conn)
    except pd.io.sql.DatabaseError: youth_df = generate_sample_youth_data()
    
    overall_data = youth_df.groupby('ì—°ë ¹ê³„ì¸µë³„', as_index=False).sum(numeric_only=True)
    overall_data["ì„±ë³„"] = "ì „ì²´"
    rate_cols = [col for col in youth_df.columns if "_ì‹¤ì—…ë¥ " in col]
    mean_rates = youth_df.groupby('ì—°ë ¹ê³„ì¸µë³„')[rate_cols].mean().reset_index()
    for col in rate_cols: overall_data[col] = overall_data['ì—°ë ¹ê³„ì¸µë³„'].map(mean_rates.set_index('ì—°ë ¹ê³„ì¸µë³„')[col])
    youth_df = pd.concat([youth_df, overall_data], ignore_index=True)

    id_vars = ["ì„±ë³„", "ì—°ë ¹ê³„ì¸µë³„"]
    unemp_long = youth_df.melt(id_vars=id_vars, value_vars=rate_cols, var_name="ì›”", value_name="ì‹¤ì—…ë¥ ")
    pop_long = youth_df.melt(id_vars=id_vars, value_vars=[c for c in youth_df.columns if "_ê²½ì œí™œë™ì¸êµ¬" in c], var_name="ì›”", value_name="ê²½ì œí™œë™ì¸êµ¬")
    emp_long = youth_df.melt(id_vars=id_vars, value_vars=[c for c in youth_df.columns if "_ì·¨ì—…ì" in c], var_name="ì›”", value_name="ì·¨ì—…ì")
    unemp_long["ì›”"], pop_long["ì›”"], emp_long["ì›”"] = [df["ì›”"].str.replace(s, "") for df, s in [(unemp_long, "_ì‹¤ì—…ë¥ "), (pop_long, "_ê²½ì œí™œë™ì¸êµ¬"), (emp_long, "_ì·¨ì—…ì")]]
    trend_df = unemp_long.merge(pop_long, on=id_vars+["ì›”"]).merge(emp_long, on=id_vars+["ì›”"])
    trend_df["ì›”"] = pd.to_datetime(trend_df["ì›”"], format="%Y.%m").dt.strftime("%Y.%m")
    trend_df = trend_df.sort_values("ì›”")
    return trend_df, skills_df, levels_df, rallit_df

@st.cache_resource
def load_llama_model(model_id):
    try:
        llm = Llama(model_id=model_id)
        return llm
    except Exception:
        st.sidebar.error(f"'{model_id}' ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨. ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.", icon="ğŸš¨")
        st.sidebar.code(f"llama model download --source meta --model-id {model_id}", language="bash")
        return None

# --- 4. ë¶„ì„ ë° ì‹œê°í™” í•¨ìˆ˜ ---
@st.cache_data
def create_word_cloud(df):
    d = dict(zip(df['ê¸°ìˆ ìŠ¤íƒ'], df['ë¹ˆë„']))
    system = platform.system()
    font_path = 'NanumGothic.ttf' if Path('NanumGothic.ttf').exists() else ('malgun' if system == 'Windows' else None)
    wc = WordCloud(font_path=font_path, background_color='white', width=400, height=300, colormap='viridis').generate_from_frequencies(d)
    return wc

def show_trend_chart(df, age_group):
    st.markdown("---")
    st.markdown(f"#### ğŸ“ˆ {age_group} ê³ ìš© ì‹œê³„ì—´ ì¶”ì´ (ì „ì²´ ì„±ë³„ ê¸°ì¤€)")
    overall = df[(df["ì„±ë³„"] == "ì „ì²´") & (df["ì—°ë ¹ê³„ì¸µë³„"] == age_group)].sort_values("ì›”")
    if overall.empty: st.info("ì„ íƒëœ ì—°ë ¹ëŒ€ì˜ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    col = st.selectbox("ğŸ“Š ì‹œê³„ì—´ í•­ëª© ì„ íƒ", ["ì‹¤ì—…ë¥ ", "ê²½ì œí™œë™ì¸êµ¬", "ì·¨ì—…ì"], key="trend_col")
    fig = px.line(overall, x="ì›”", y=col, title=f"{col} ì›”ë³„ ì¶”ì´", markers=True)
    if col == "ì‹¤ì—…ë¥ ": hovertemplate = "<b>ì›”</b>: %{x}<br><b>ì‹¤ì—…ë¥ </b>: %{y:.1f}%"
    else: hovertemplate = f"<b>ì›”</b>: %{{x}}<br><b>{col}</b>: %{{y:,.0f}}ëª…"
    fig.update_traces(line_shape="spline", hovertemplate=hovertemplate)
    st.plotly_chart(fig, use_container_width=True)

job_category_map = { "ë°ì´í„° ë¶„ì„": ["ë°ì´í„°", "ë¶„ì„", "Data", "BI"], "ë§ˆì¼€íŒ…": ["ë§ˆì¼€íŒ…", "ë§ˆì¼€í„°", "Marketing", "ê´‘ê³ ", "ì½˜í…ì¸ "], "ê¸°íš": ["ê¸°íš", "PM", "PO", "ì„œë¹„ìŠ¤", "Product"], "í”„ë¡ íŠ¸ì—”ë“œ": ["í”„ë¡ íŠ¸ì—”ë“œ", "Frontend", "React", "Vue", "ì›¹ ê°œë°œ"], "ë°±ì—”ë“œ": ["ë°±ì—”ë“œ", "Backend", "Java", "Python", "ì„œë²„", "Node.js"], "AI/ML": ["AI", "ML", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ì¸ê³µì§€ëŠ¥"], "ë””ìì¸": ["ë””ìì¸", "ë””ìì´ë„ˆ", "Designer", "UI", "UX", "BX", "ê·¸ë˜í”½"], "ì˜ì—…": ["ì˜ì—…", "Sales", "ì„¸ì¼ì¦ˆ", "ë¹„ì¦ˆë‹ˆìŠ¤", "Business Development"], "ê³ ê°ì§€ì›": ["CS", "CX", "ê³ ê°", "ì§€ì›", "ì„œë¹„ìŠ¤ ìš´ì˜"], "ì¸ì‚¬": ["ì¸ì‚¬", "HR", "ì±„ìš©", "ì¡°ì§ë¬¸í™”", "Recruiting"] }
def calculate_job_fit(work_style, work_env, interest_job):
    job_fit_scores = {}
    for job in job_category_map.keys():
        score = 0
        if "ë¶„ì„" in work_style and any(k in job for k in ["ë°ì´í„°", "AI/ML", "ë°±ì—”ë“œ"]): score += 50
        elif "ì°½ì˜" in work_style and any(k in job for k in ["ë§ˆì¼€íŒ…", "ë””ìì¸", "ê¸°íš"]): score += 50
        if "ë…ë¦½" in work_env and any(k in job for k in ["ì—”ë“œ", "ë¶„ì„", "AI/ML"]): score += 40
        elif "íŒ€ì›Œí¬" in work_env and any(k in job for k in ["ê¸°íš", "ë§ˆì¼€íŒ…", "ë””ìì¸"]): score += 40
        if job == interest_job: score += 15
        job_fit_scores[job] = min(100, score + 5)
    return job_fit_scores

# --- 5. ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.title("My Job-Fit Profile")
    with st.container(border=True):
        st.header("ğŸ‘¤ ë‚˜ì˜ í”„ë¡œí•„ ì„¤ì •")
        job_options = sorted(list(job_category_map.keys()))
        interest_job = st.selectbox("ê´€ì‹¬ ì§ë¬´", job_options, key="interest_job")
        career_options = ["ìƒê´€ ì—†ìŒ", "ì‹ ì…", "1-3ë…„", "4-6ë…„", "7-10ë…„ ì´ìƒ"]
        career_level = st.selectbox("í¬ë§ ê²½ë ¥ ìˆ˜ì¤€", career_options, key="career_level")
    with st.container(border=True):
        st.header("ğŸ§  ë‚˜ì˜ ì„±í–¥ ì§„ë‹¨")
        work_style = st.radio("ì„ í˜¸í•˜ëŠ” ì—…ë¬´ ìŠ¤íƒ€ì¼ì€?", ["ë¶„ì„ì ì´ê³  ë…¼ë¦¬ì ", "ì°½ì˜ì ì´ê³  í˜ì‹ ì ", "ì²´ê³„ì ì´ê³  ê³„íšì ", "ì‚¬êµì ì´ê³  í˜‘ë ¥ì "], key="work_style")
        work_env = st.radio("ì„ í˜¸í•˜ëŠ” ì—…ë¬´ í™˜ê²½ì€?", ["ë…ë¦½ì ìœ¼ë¡œ ì¼í•˜ê¸°", "íŒ€ì›Œí¬ ì¤‘ì‹¬", "ë¹ ë¥¸ ë³€í™”ì™€ ë„ì „", "ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ"], key="work_env")
    with st.container(border=True):
        st.header("ğŸ¦™ AI ë„ìš°ë¯¸ ì„¤ì •")
        selected_model_id = st.text_input("ì‚¬ìš©í•  Llama ëª¨ë¸ ID", "llama-4-scout-17b-16e-instruct")
        temperature = st.slider("Temperature (ì°½ì˜ì„±)", 0.0, 1.0, 0.1, 0.05)
        max_tokens = st.slider("Max Tokens (ë‹µë³€ ê¸¸ì´)", 128, 4096, 1024, 128)

# --- 6. ë©”ì¸ ë¡œì§ ì‹¤í–‰ ---
conn = init_connection()
trend_df, skills_df, levels_df, rallit_df = load_all_data(conn)
llm = load_llama_model(selected_model_id)
job_fit_scores = calculate_job_fit(work_style, work_env, interest_job)
score_df = pd.DataFrame(job_fit_scores.items(), columns=["ì§ë¬´", "ì í•©ë„"]).sort_values("ì í•©ë„", ascending=False).reset_index(drop=True)
top_job = score_df.iloc[0]["ì§ë¬´"] if not score_df.empty else "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"


# --- 7. ëŒ€ì‹œë³´ë“œ ë³¸ë¬¸ ---
st.markdown('<div class="main-header"><h1>ğŸ§  Job-Fit Insight Dashboard</h1><p>ë‚˜ì˜ ì„±í–¥ê³¼ ì‹œì¥ ë°ì´í„°ë¥¼ ê²°í•©í•œ ìµœì ì˜ ì»¤ë¦¬ì–´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.</p></div>', unsafe_allow_html=True)
main_tabs = st.tabs(["ğŸš€ ë‚˜ì˜ ë§ì¶¤ ë¶„ì„", "ğŸ“Š ì‹œì¥ ë™í–¥ ë¶„ì„", "ğŸ¦™ Llama 4 AI ë„ìš°ë¯¸"])

with main_tabs[0]:
    st.subheader(f"ì‚¬ìš©ìë‹˜ì„ ìœ„í•œ ë§ì¶¤ ì§ë¬´ ë¶„ì„")
    # (ì´í•˜ ë§ì¶¤ ë¶„ì„ íƒ­ UIëŠ” ì´ì „ê³¼ ë™ì¼)
    # ...

with main_tabs[1]:
    st.subheader("ëŒ€í•œë¯¼êµ­ ì±„ìš© ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„")
    # (ì´í•˜ ì‹œì¥ ë™í–¥ íƒ­ UIëŠ” ì´ì „ê³¼ ë™ì¼)
    # ...

with main_tabs[2]:
    st.subheader("Llama 4 Scout ê¸°ë°˜ AI ë¶„ì„")
    if llm is None:
        st.error("AI ë„ìš°ë¯¸ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        ai_feature_tabs = st.tabs(["**ğŸ“„ AI ì§ë¬´ ë¶„ì„**", "**ğŸ’¬ AI ì»¤ë¦¬ì–´ ìƒë‹´**"])
        with ai_feature_tabs[0]:
            st.markdown("##### ì±„ìš© ê³µê³ ë¥¼ ì…ë ¥í•˜ë©´ Llama 4ê°€ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤.")
            job_desc_input = st.text_area("ì—¬ê¸°ì— ì±„ìš© ê³µê³ ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:", height=250, placeholder="ì˜ˆì‹œ: 'ë©”íƒ€ì—ì„œ Llama 4ë¥¼ ë‹¤ë£° AI ì—”ì§€ë‹ˆì–´ë¥¼ ì°¾ìŠµë‹ˆë‹¤...'")
            if st.button("ë¶„ì„ ì‹œì‘í•˜ê¸°", key="analyze_job"):
                if not job_desc_input:
                    st.warning("ë¶„ì„í•  ì±„ìš© ê³µê³ ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("Llama 4 Scoutê°€ ì±„ìš© ê³µê³ ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        system_prompt = "You are a professional HR analyst. Analyze a job description and provide a structured summary in Korean."
                        user_prompt = f"Analyze the following job description and provide the output in the specified format below.\n\n**Job Description:**\n---\n{job_desc_input}\n---\n\n**Output Format:**\n### ğŸ“ í•µì‹¬ ìš”ì•½ (3ê°€ì§€)\n- [í•µì‹¬ ì—­í• ]\n- [í•µì‹¬ ì—­í• ]\n- [í•µì‹¬ ì—­í• ]\n### ğŸ› ï¸ ìš”êµ¬ ê¸°ìˆ  ìŠ¤íƒ\n- [ê¸°ìˆ  1], [ê¸°ìˆ  2], ...\n### ğŸ“ˆ ì˜ˆìƒ ê²½ë ¥ ìˆ˜ì¤€\n- [ì˜ˆ: ì‹ ì…, 1~3ë…„ì°¨, 5ë…„ ì´ìƒ ë“±]\n### ğŸ—£ï¸ ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸ (3ê°€ì§€)\n1. [ê¸°ìˆ  ì§ˆë¬¸]\n2. [ê²½í—˜ ì§ˆë¬¸]\n3. [ë¬¸í™” ì í•©ì„± ì§ˆë¬¸]"
                        response = llm.create_chat_completion(messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], temperature=temperature, max_tokens=max_tokens)
                        analysis_result = response['choices'][0]['message']['content']
                    st.markdown("---"); st.subheader("ğŸ¤– Llama 4 Scout ë¶„ì„ ê²°ê³¼"); st.markdown(analysis_result)
        with ai_feature_tabs[1]:
            st.markdown("##### í˜„ì¬ ë‚˜ì˜ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ì»¤ë¦¬ì–´ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
            user_profile = f"ì €ëŠ” **{interest_job}** ì§ë¬´ì— ê´€ì‹¬ì´ ìˆê³ , í¬ë§ ê²½ë ¥ì€ **{career_level}** ì…ë‹ˆë‹¤. ì €ì˜ ì„±í–¥ì€ **{work_style}**í•˜ê³ , **{work_env}** í™˜ê²½ì„ ì„ í˜¸í•©ë‹ˆë‹¤."
            st.info(f"**í˜„ì¬ í”„ë¡œí•„:** {user_profile}")
            question_examples = [f"{interest_job} ì§ë¬´ë¡œ ì„±ì¥í•˜ê¸° ìœ„í•œ í•™ìŠµ ë¡œë“œë§µì„ ì§œì£¼ì„¸ìš”.", "ì´ í”„ë¡œí•„ì— ì–´ìš¸ë¦¬ëŠ” ë‹¤ë¥¸ ì§ë¬´ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.", "ì œ ì„±í–¥ì— ë§ëŠ” íšŒì‚¬ë¥¼ ì°¾ìœ¼ë ¤ë©´ ì–´ë–¤ ì ì„ ê³ ë ¤í•´ì•¼ í• ê¹Œìš”?"]
            selected_question = st.selectbox("ì§ˆë¬¸ ì˜ˆì‹œë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:", [""] + question_examples)
            user_question = st.text_input("ì§ˆë¬¸ ì…ë ¥:", value=selected_question)
            if st.button("Llamaì—ê²Œ ì§ˆë¬¸í•˜ê¸°", key="ask_career"):
                if not user_question:
                    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("Llama 4 Scoutê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        system_prompt = "You are a friendly and insightful career counselor. Based on the user's profile, answer their career-related questions in Korean."
                        full_prompt = f"**User Profile:**\n{user_profile}\n\n**User Question:**\n{user_question}"
                        response = llm.create_chat_completion(messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": full_prompt}], temperature=temperature, max_tokens=max_tokens)
                        career_advice = response['choices'][0]['message']['content']
                    st.markdown("---"); st.subheader("ğŸ¤– Llama 4 Scout ì»¤ë¦¬ì–´ ì¡°ì–¸"); st.markdown(career_advice)

# 8. í‘¸í„°
st.markdown("---")
st.markdown('<div style="text-align: center; color: #666;"><p>ğŸ§  Job-Fit Insight Dashboard | Powered by Streamlit & Llama 4</p></div>', unsafe_allow_html=True)

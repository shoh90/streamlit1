import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
from pathlib import Path
import glob
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import platform
from groq import Groq

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="Job-Fit Insight Dashboard with AI",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. CSS ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .main-header { background: linear-gradient(90deg, #1f4e79 0%, #2980b9 100%); padding: 1.5rem; border-radius: 10px; color: white; margin-bottom: 2rem; }
    .highlight-card { background: white; padding: 1.5rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); border-left: 5px solid #ff6b35; }
    .job-posting-card { background: #ffffff; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 1rem; border: 1px solid #e9ecef; }
    .job-posting-card a { text-decoration: none; color: #1f4e79; font-weight: bold; font-size: 1.1em; }
    .job-posting-card p { margin: 0.3rem 0; color: #495057; font-size: 0.9em; }
    div[data-testid="metric-container"] { background-color: #f8f9fa; border-left: 5px solid #2980b9; padding: 1rem; border-radius: 10px; }
</style>
""", unsafe_allow_html=True)


# --- 3. ë°ì´í„° ë¡œë”© ë° ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_resource
def init_connection(db_path="data/job_fit_insight.db"):
    db_file = Path(db_path)
    if not db_file.exists():
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼('{db_path}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `setup_database.py`ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        st.stop()
    return sqlite3.connect(db_file, check_same_thread=False)

def generate_sample_youth_data():
    data = {'ì„±ë³„': ['ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨ì„±', 'ì—¬ì„±'], 'ì—°ë ¹ê³„ì¸µë³„': ['15-29ì„¸', '15-29ì„¸', '30-39ì„¸', '30-39ì„¸'], '2025.03_ì‹¤ì—…ë¥ ': [6.8, 6.1, 3.1, 3.5], '2025.03_ê²½ì œí™œë™ì¸êµ¬': [2450000, 2150000, 3400000, 3100000], '2025.03_ì·¨ì—…ì': [2283000, 2018000, 3295000, 2990000], '2025.04_ì‹¤ì—…ë¥ ': [7.0, 6.3, 3.2, 3.6], '2025.04_ê²½ì œí™œë™ì¸êµ¬': [2460000, 2160000, 3420000, 3120000], '2025.04_ì·¨ì—…ì': [2287000, 2023000, 3310000, 3010000], '2025.05_ì‹¤ì—…ë¥ ': [6.9, 6.2, 3.0, 3.4], '2025.05_ê²½ì œí™œë™ì¸êµ¬': [2470000, 2170000, 3430000, 3130000], '2025.05_ì·¨ì—…ì': [2299000, 2035000, 3325000, 3020000]}
    return pd.DataFrame(data)

@st.cache_data
def load_all_data(_conn):
    skills_df = pd.read_sql("SELECT * FROM top10_skills_per_job", _conn)
    levels_df = pd.read_sql("SELECT * FROM joblevel_counts", _conn)
    rallit_df = None
    try:
        csv_files = glob.glob(str(Path("data") / "rallit_*.csv"))
        if csv_files:
            rallit_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True).drop_duplicates(subset=['url']).reset_index(drop=True)
    except Exception as e:
        print(f"Error loading Rallit CSVs: {e}")
    try:
        youth_df = pd.read_sql("SELECT * FROM youth_summary", _conn)
    except pd.io.sql.DatabaseError:
        youth_df = generate_sample_youth_data()
    
    overall_data = youth_df.groupby('ì—°ë ¹ê³„ì¸µë³„', as_index=False).sum(numeric_only=True)
    overall_data["ì„±ë³„"] = "ì „ì²´"
    rate_cols = [col for col in youth_df.columns if "_ì‹¤ì—…ë¥ " in col]
    mean_rates = youth_df.groupby('ì—°ë ¹ê³„ì¸µë³„')[rate_cols].mean().reset_index()
    for col in rate_cols:
        overall_data[col] = overall_data['ì—°ë ¹ê³„ì¸µë³„'].map(mean_rates.set_index('ì—°ë ¹ê³„ì¸µë³„')[col])
    youth_df = pd.concat([youth_df, overall_data], ignore_index=True)

    id_vars = ["ì„±ë³„", "ì—°ë ¹ê³„ì¸µë³„"]
    unemp_long = youth_df.melt(id_vars=id_vars, value_vars=rate_cols, var_name="ì›”", value_name="ì‹¤ì—…ë¥ ")
    pop_long = youth_df.melt(id_vars=id_vars, value_vars=[c for c in youth_df.columns if "_ê²½ì œí™œë™ì¸êµ¬" in c], var_name="ì›”", value_name="ê²½ì œí™œë™ì¸êµ¬")
    emp_long = youth_df.melt(id_vars=id_vars, value_vars=[c for c in youth_df.columns if "_ì·¨ì—…ì" in c], var_name="ì›”", value_name="ì·¨ì—…ì")
    unemp_long["ì›”"], pop_long["ì›”"], emp_long["ì›”"] = [df["ì›”"].str.replace(s, "") for df, s in [(unemp_long, "_ì‹¤ì—…ë¥ "), (pop_long, "_ê²½ì œí™œë™ì¸êµ¬"), (emp_long, "_ì·¨ì—…ì")]]
    trend_df = unemp_long.merge(pop_long, on=id_vars + ["ì›”"]).merge(emp_long, on=id_vars + ["ì›”"])
    trend_df["ì›”"] = pd.to_datetime(trend_df["ì›”"], format="%Y.%m").dt.strftime("%Y.%m")
    trend_df = trend_df.sort_values("ì›”")
    return trend_df, skills_df, levels_df, rallit_df

@st.cache_data
def create_word_cloud(df):
    d = dict(zip(df['ê¸°ìˆ ìŠ¤íƒ'], df['ë¹ˆë„']))
    system = platform.system()
    font_path = 'NanumGothic.ttf' if Path('NanumGothic.ttf').exists() else ('malgun' if system == 'Windows' else None)
    if font_path is None:
        return None
    wc = WordCloud(font_path=font_path, background_color='white', width=400, height=300, colormap='viridis').generate_from_frequencies(d)
    return wc

def show_trend_chart(df, age_group):
    st.markdown("---")
    st.markdown(f"#### ğŸ“ˆ {age_group} ê³ ìš© ì‹œê³„ì—´ ì¶”ì´ (ì „ì²´ ì„±ë³„ ê¸°ì¤€)")
    overall = df[(df["ì„±ë³„"] == "ì „ì²´") & (df["ì—°ë ¹ê³„ì¸µë³„"] == age_group)].sort_values("ì›”")
    if overall.empty:
        st.info("ì„ íƒëœ ì—°ë ¹ëŒ€ì˜ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    col = st.selectbox("ğŸ“Š ì‹œê³„ì—´ í•­ëª© ì„ íƒ", ["ì‹¤ì—…ë¥ ", "ê²½ì œí™œë™ì¸êµ¬", "ì·¨ì—…ì"], key="trend_col")
    fig = px.line(overall, x="ì›”", y=col, title=f"{col} ì›”ë³„ ì¶”ì´", markers=True)
    if col == "ì‹¤ì—…ë¥ ":
        hovertemplate = "<b>ì›”</b>: %{x}<br><b>ì‹¤ì—…ë¥ </b>: %{y:.1f}%"
    else:
        hovertemplate = f"<b>ì›”</b>: %{{x}}<br><b>{col}</b>: %{{y:,.0f}}ëª…"
    fig.update_traces(line_shape="spline", hovertemplate=hovertemplate)
    st.plotly_chart(fig, use_container_width=True)

# --- 4. ë¶„ì„ ë¡œì§ ---
job_category_map = { "ë°ì´í„° ë¶„ì„": ["ë°ì´í„°", "ë¶„ì„", "Data", "BI"], "ë§ˆì¼€íŒ…": ["ë§ˆì¼€íŒ…", "ë§ˆì¼€í„°", "Marketing", "ê´‘ê³ ", "ì½˜í…ì¸ "], "ê¸°íš": ["ê¸°íš", "PM", "PO", "ì„œë¹„ìŠ¤", "Product"], "í”„ë¡ íŠ¸ì—”ë“œ": ["í”„ë¡ íŠ¸ì—”ë“œ", "Frontend", "React", "Vue", "ì›¹ ê°œë°œ"], "ë°±ì—”ë“œ": ["ë°±ì—”ë“œ", "Backend", "Java", "Python", "ì„œë²„", "Node.js"], "AI/ML": ["AI", "ML", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ì¸ê³µì§€ëŠ¥"], "ë””ìì¸": ["ë””ìì¸", "ë””ìì´ë„ˆ", "Designer", "UI", "UX", "BX", "ê·¸ë˜í”½"], "ì˜ì—…": ["ì˜ì—…", "Sales", "ì„¸ì¼ì¦ˆ", "ë¹„ì¦ˆë‹ˆìŠ¤", "Business Development"], "ê³ ê°ì§€ì›": ["CS", "CX", "ê³ ê°", "ì§€ì›", "ì„œë¹„ìŠ¤ ìš´ì˜"], "ì¸ì‚¬": ["ì¸ì‚¬", "HR", "ì±„ìš©", "ì¡°ì§ë¬¸í™”", "Recruiting"] }
def calculate_job_fit(work_style, work_env, interest_job):
    job_fit_scores = {}
    for job in job_category_map.keys():
        score = 0
        if "ë¶„ì„" in work_style and any(k in job for k in ["ë°ì´í„°", "AI/ML", "ë°±ì—”ë“œ"]): score += 50
        elif "ì°½ì˜" in work_style and any(k in job for k in ["ë§ˆì¼€íŒ…", "ë””ìì¸", "ê¸°íš"]): score += 50
        if "ë…ë¦½" in work_env and any(k in job for k in ["ì—”ë“œ", "ë¶„ì„", "AI/ML"]): score += 40
        elif "íŒ€ì›Œí¬" in work_env and any(k in job for k in ["ê¸°íš", "ë§ˆì¼€íŒ…", "ë””ìì¸"]): score += 40
        if job == interest_job: score += 15
        job_fit_scores[job] = min(100, score + 5)
    return job_fit_scores

def prepare_ai_analysis_data(skills_df, levels_df, rallit_df, interest_job, career_level):
    context_text = ""
    skills_info = skills_df[skills_df['ì§ë¬´'] == interest_job]
    if not skills_info.empty:
        context_text += f"### [{interest_job} ì§ë¬´ ì‹œì¥ì˜ ì£¼ìš” ê¸°ìˆ ìŠ¤íƒ]\n"
        context_text += skills_info[['ê¸°ìˆ ìŠ¤íƒ', 'ë¹ˆë„']].to_markdown(index=False) + "\n\n"
    levels_info = levels_df[levels_df['ì§ë¬´'] == interest_job]
    if not levels_info.empty:
        context_text += f"### [{interest_job} ì§ë¬´ ì‹œì¥ì˜ ê²½ë ¥ ë ˆë²¨ ë¶„í¬]\n"
        context_text += levels_info[['jobLevels', 'ê³µê³ ìˆ˜']].to_markdown(index=False) + "\n\n"
    if rallit_df is not None and all(col in rallit_df.columns for col in ['title', 'jobLevels', 'companyName']):
        search_keywords = job_category_map.get(interest_job, [interest_job])
        keyword_regex = '|'.join(search_keywords)
        job_mask = rallit_df["title"].str.contains(keyword_regex, case=False, na=False)
        if career_level == "ìƒê´€ ì—†ìŒ": career_mask = pd.Series(True, index=rallit_df.index)
        elif career_level == "ì‹ ì…": career_mask = rallit_df["jobLevels"].str.contains("ì‹ ì…|ê²½ë ¥ ë¬´ê´€|JUNIOR", case=False, na=False)
        else: career_mask = rallit_df["jobLevels"].str.contains(career_level.replace('-','~'), case=False, na=False)
        filtered_jobs = rallit_df[job_mask & career_mask].head(3)
        if not filtered_jobs.empty:
            context_text += "### [í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ì±„ìš© ê³µê³  ì˜ˆì‹œ]\n"
            context_text += filtered_jobs[['title', 'companyName', 'jobLevels']].to_markdown(index=False) + "\n\n"
    return context_text if context_text else "ë¶„ì„í•  ì‹œì¥ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

# --- 5. ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.title("My Job-Fit Profile")
    with st.container(border=True):
        st.header("ğŸ‘¤ ë‚˜ì˜ í”„ë¡œí•„ ì„¤ì •")
        job_options = sorted(list(job_category_map.keys()))
        interest_job = st.selectbox("ê´€ì‹¬ ì§ë¬´", job_options, key="interest_job")
        career_options = ["ìƒê´€ ì—†ìŒ", "ì‹ ì…", "1-3ë…„", "4-6ë…„", "7-10ë…„ ì´ìƒ"]
        career_level = st.selectbox("í¬ë§ ê²½ë ¥ ìˆ˜ì¤€", career_options, key="career_level")
    with st.container(border=True):
        st.header("ğŸ§  ë‚˜ì˜ ì„±í–¥ ì§„ë‹¨")
        work_style = st.radio("ì„ í˜¸í•˜ëŠ” ì—…ë¬´ ìŠ¤íƒ€ì¼ì€?", ["ë¶„ì„ì ì´ê³  ë…¼ë¦¬ì ", "ì°½ì˜ì ì´ê³  í˜ì‹ ì ", "ì²´ê³„ì ì´ê³  ê³„íšì ", "ì‚¬êµì ì´ê³  í˜‘ë ¥ì "], key="work_style")
        work_env = st.radio("ì„ í˜¸í•˜ëŠ” ì—…ë¬´ í™˜ê²½ì€?", ["ë…ë¦½ì ìœ¼ë¡œ ì¼í•˜ê¸°", "íŒ€ì›Œí¬ ì¤‘ì‹¬", "ë¹ ë¥¸ ë³€í™”ì™€ ë„ì „", "ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ"], key="work_env")
    with st.container(border=True):
        st.header("ğŸ¦™ AI ë„ìš°ë¯¸ ì„¤ì •")
        selected_model = st.selectbox("ì‚¬ìš©í•  AI ëª¨ë¸", ["llama3-70b-8192", "llama3-8b-8192", "mixtral-8x7b-32768"])
        temperature = st.slider("Temperature (ì°½ì˜ì„±)", 0.0, 1.0, 0.2, 0.05)
        max_tokens = st.slider("Max Tokens (ë‹µë³€ ê¸¸ì´)", 128, 8192, 1500, 128)

# --- 6. ë©”ì¸ ë¡œì§ ì‹¤í–‰ ---
conn = init_connection()
trend_df, skills_df, levels_df, rallit_df = load_all_data(conn)
client = Groq(api_key=st.secrets.get("GROQ_API_KEY")) if "GROQ_API_KEY" in st.secrets and st.secrets.get("GROQ_API_KEY") else None
job_fit_scores = calculate_job_fit(work_style, work_env, interest_job)
score_df = pd.DataFrame(job_fit_scores.items(), columns=["ì§ë¬´", "ì í•©ë„"]).sort_values("ì í•©ë„", ascending=False).reset_index(drop=True)
top_job = score_df.iloc[0]["ì§ë¬´"] if not score_df.empty else "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

# --- 7. ëŒ€ì‹œë³´ë“œ ë³¸ë¬¸ ---
st.markdown('<div class="main-header"><h1>ğŸ§  Job-Fit Insight Dashboard</h1><p>ë‚˜ì˜ ì„±í–¥ê³¼ ì‹œì¥ ë°ì´í„°ë¥¼ ê²°í•©í•œ ìµœì ì˜ ì»¤ë¦¬ì–´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.</p></div>', unsafe_allow_html=True)
main_tabs = st.tabs(["ğŸš€ ë‚˜ì˜ ë§ì¶¤ ë¶„ì„", "ğŸ“Š ì‹œì¥ ë™í–¥ ë¶„ì„", "ğŸ¦™ AI ë„ìš°ë¯¸"])

with main_tabs[0]:
    st.subheader(f"ì‚¬ìš©ìë‹˜ì„ ìœ„í•œ ë§ì¶¤ ì§ë¬´ ë¶„ì„")
    col1, col2 = st.columns([0.5, 0.5])
    with col1:
        st.markdown('<div class="highlight-card" style="height: 100%;">', unsafe_allow_html=True)
        st.markdown(f"<h4>ğŸ† ìµœì  ì¶”ì²œ ì§ë¬´</h4><h1>{top_job}</h1>", unsafe_allow_html=True)
        progress_value = score_df.iloc[0]["ì í•©ë„"]
        st.progress(int(progress_value) / 100)
        st.markdown(f"**ì í•©ë„: {progress_value}%**")
        st.markdown("---")
        st.markdown("##### ğŸ” ë¶„ì„ ìš”ì•½")
        st.markdown(f"âœ“ **'{work_style}'** ì„±í–¥ê³¼ **'{work_env}'** í™˜ê²½ ì„ í˜¸,")
        st.markdown(f"âœ“ ê·¸ë¦¬ê³  **'{interest_job}'** ì§ë¬´ì— ëŒ€í•œ ê´€ì‹¬ì„ ì¢…í•©í–ˆì„ ë•Œ,")
        st.markdown(f"â” **<span style='color:#ff6b35; font-weight:bold;'>{top_job}</span>** ì§ë¬´ë¥¼ ê°€ì¥ ì¶”ì²œí•©ë‹ˆë‹¤!", unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
    with col2:
        skills_to_show_top = skills_df[skills_df["ì§ë¬´"] == top_job]
        skills_to_show_interest = skills_df[skills_df["ì§ë¬´"] == interest_job]
        levels_to_show_top = levels_df[levels_df['ì§ë¬´'] == top_job]
        if not skills_to_show_top.empty:
            st.markdown(f"##### âœ¨ **'{top_job}' ì§ë¬´ í•µì‹¬ ì—­ëŸ‰**")
            skill_tabs = st.tabs(["ğŸ“Š ê¸°ìˆ  ìŠ¤íƒ ë¹ˆë„", "â˜ï¸ ì›Œë“œ í´ë¼ìš°ë“œ"])
            with skill_tabs[0]:
                fig_skill = px.bar(skills_to_show_top.sort_values("ë¹ˆë„", ascending=True), x="ë¹ˆë„", y="ê¸°ìˆ ìŠ¤íƒ", orientation='h', title=f"'{top_job}' í•µì‹¬ ê¸°ìˆ ")
                fig_skill.update_layout(yaxis_title="", height=400)
                st.plotly_chart(fig_skill, use_container_width=True)
            with skill_tabs[1]:
                wc = create_word_cloud(skills_to_show_top)
                if wc:
                    fig, ax = plt.subplots(); ax.imshow(wc, interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)
                else:
                    st.info("ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif not skills_to_show_interest.empty:
            st.info(f"'{top_job}'ì˜ ìŠ¤í‚¬ ì •ë³´ê°€ ì—†ì–´, ê´€ì‹¬ ì§ë¬´ **'{interest_job}'**ì˜ ì •ë³´ë¥¼ ëŒ€ì‹  í‘œì‹œí•©ë‹ˆë‹¤.")
            skill_tabs = st.tabs(["ğŸ“Š ê¸°ìˆ  ìŠ¤íƒ ë¹ˆë„", "â˜ï¸ ì›Œë“œ í´ë¼ìš°ë“œ"])
            with skill_tabs[0]:
                fig_skill = px.bar(skills_to_show_interest.sort_values("ë¹ˆë„", ascending=True), x="ë¹ˆë„", y="ê¸°ìˆ ìŠ¤íƒ", orientation='h', title=f"'{interest_job}' í•µì‹¬ ê¸°ìˆ  (ê´€ì‹¬ ì§ë¬´)")
                st.plotly_chart(fig_skill, use_container_width=True)
            with skill_tabs[1]:
                wc = create_word_cloud(skills_to_show_interest)
                if wc:
                    fig, ax = plt.subplots(); ax.imshow(wc, interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)
                else:
                    st.info("ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif not levels_to_show_top.empty:
            with st.container(border=True):
                st.warning(f"'{top_job}' ì§ë¬´ì˜ ìƒì„¸ ìŠ¤í‚¬ ì •ë³´ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info(f"ëŒ€ì‹  ì‹œì¥ì˜ **'{top_job}' ì§ë¬´ ê²½ë ¥ ë¶„í¬**ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”!")
                fig_pie = px.pie(levels_to_show_top, names='jobLevels', values='ê³µê³ ìˆ˜', title=f"'{top_job}' ì§ë¬´ ê²½ë ¥ ë¶„í¬", hole=0.3)
                fig_pie.update_traces(textinfo='percent+label')
                st.plotly_chart(fig_pie, use_container_width=True)
        else:
            with st.container(border=True):
                st.warning("ì¶”ì²œ ì§ë¬´ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                st.info("ìƒë‹¨ì˜ **'ì‹œì¥ ë™í–¥ ë¶„ì„'** íƒ­ì—ì„œ ë‹¤ì–‘í•œ ì§ë¬´ì˜ íŠ¸ë Œë“œë¥¼ ì§ì ‘ íƒìƒ‰í•´ë³´ì„¸ìš”!")
    
    st.markdown("---")
    st.subheader("ğŸ“Œ ë‚˜ì—ê²Œ ë§ëŠ” Rallit ì±„ìš©ê³µê³ ")
    if rallit_df is not None:
        required_cols = ['title', 'jobLevels']
        if all(col in rallit_df.columns for col in required_cols):
            search_keywords = job_category_map.get(interest_job, [interest_job])
            keyword_regex = '|'.join(search_keywords)
            job_mask = rallit_df["title"].str.contains(keyword_regex, case=False, na=False)
            if career_level == "ìƒê´€ ì—†ìŒ": career_mask = pd.Series(True, index=rallit_df.index)
            elif career_level == "ì‹ ì…": career_mask = rallit_df["jobLevels"].str.contains("ì‹ ì…|ê²½ë ¥ ë¬´ê´€|JUNIOR", case=False, na=False)
            else: career_mask = rallit_df["jobLevels"].str.contains(career_level.replace('-','~'), case=False, na=False)
            filtered_jobs = rallit_df[job_mask & career_mask]
            top_jobs = filtered_jobs.head(5)
            if not top_jobs.empty:
                for _, row in top_jobs.iterrows():
                    st.markdown(f"""<div class="job-posting-card"><a href="{row['url']}" target="_blank">{row['title']}</a><p>ğŸ¢ **íšŒì‚¬:** {row.get('companyName', 'ì •ë³´ ì—†ìŒ')} | ğŸ“ **ì§€ì—­:** {row.get('addressRegion', 'ì •ë³´ ì—†ìŒ')}</p><p>ğŸ› ï¸ **ê¸°ìˆ ìŠ¤íƒ:** {row.get('jobSkillKeywords', 'ì •ë³´ ì—†ìŒ')}</p></div>""", unsafe_allow_html=True)
            else: st.info(f"'{interest_job}' ì§ë¬´ì™€ '{career_level}' ìˆ˜ì¤€ì— ë§ëŠ” ì±„ìš© ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else: st.error(f"Rallit ë°ì´í„° íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼('title', 'jobLevels')ì´ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì˜ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else: st.warning("â— ë ë¦¿ ì±„ìš©ê³µê³  ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `data` í´ë”ì— `rallit_*.csv` íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

with main_tabs[1]:
    st.subheader("ëŒ€í•œë¯¼êµ­ ì±„ìš© ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„")
    market_tabs = st.tabs(["ê³ ìš© ë™í–¥", "ê¸°ìˆ  ìŠ¤íƒ", "ê²½ë ¥ ë¶„í¬"])
    with market_tabs[0]:
        if not trend_df.empty:
            age_options = sorted(trend_df["ì—°ë ¹ê³„ì¸µë³„"].unique())
            selected_age = st.selectbox("ğŸ” ì—°ë ¹ ê³„ì¸µ ì„ íƒ", age_options, index=age_options.index("15-29ì„¸") if "15-29ì„¸" in age_options else 0)
            st.markdown(f"#### **ğŸ“Š {selected_age} ê³ ìš©ì§€í‘œ**")
            month_options = sorted(trend_df["ì›”"].unique(), reverse=True)
            selected_month = st.selectbox("ğŸ—“ï¸ ì¡°íšŒí•  ì›” ì„ íƒ", month_options, key="selected_month_v4")
            filtered_trend = trend_df[trend_df['ì—°ë ¹ê³„ì¸µë³„'] == selected_age]
            current_overall_series = filtered_trend[(filtered_trend["ì›”"] == selected_month) & (filtered_trend["ì„±ë³„"] == "ì „ì²´")]
            if not current_overall_series.empty:
                current_overall = current_overall_series.iloc[0]
                current_unemployment_rate, current_active_pop_k, current_employed_pop_k = current_overall['ì‹¤ì—…ë¥ '], current_overall['ê²½ì œí™œë™ì¸êµ¬'] / 1000, current_overall['ì·¨ì—…ì'] / 1000
                delta_unemployment, delta_active, delta_employed = None, None, None
                prev_month_index = month_options.index(selected_month) + 1
                if prev_month_index < len(month_options):
                    prev_month = month_options[prev_month_index]
                    prev_overall_series = filtered_trend[(filtered_trend["ì›”"] == prev_month) & (filtered_trend["ì„±ë³„"] == "ì „ì²´")]
                    if not prev_overall_series.empty:
                        prev_overall = prev_overall_series.iloc[0]
                        delta_unemployment = f"{current_unemployment_rate - prev_overall['ì‹¤ì—…ë¥ ']:.1f}%p"
                        delta_active = f"{(current_active_pop_k - prev_overall['ê²½ì œí™œë™ì¸êµ¬']/1000):,.0f} ì²œëª…"
                        delta_employed = f"{(current_employed_pop_k - prev_overall['ì·¨ì—…ì']/1000):,.0f} ì²œëª…"
                m_col1, m_col2, m_col3 = st.columns(3)
                m_col1.metric(label="ì‹¤ì—…ë¥  (ì „ì²´)", value=f"{current_unemployment_rate:.1f}%", delta=delta_unemployment, delta_color="inverse")
                m_col2.metric(label="ê²½ì œí™œë™ì¸êµ¬ (ë‹¨ìœ„: ì²œëª…)", value=f"{current_active_pop_k:,.0f}", delta=delta_active)
                m_col3.metric(label="ì·¨ì—…ì ìˆ˜ (ë‹¨ìœ„: ì²œëª…)", value=f"{current_employed_pop_k:,.0f}", delta=delta_employed)
                show_trend_chart(trend_df, selected_age)
            else:
                st.warning(f"'{selected_age}', '{selected_month}'ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            st.warning("ê³ ìš©ì§€í‘œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    with market_tabs[1]:
        st.markdown("#### **ğŸ› ï¸ ì§ë¬´ë³„ ìƒìœ„ ê¸°ìˆ ìŠ¤íƒ TOP 10**")
        job_to_show = st.selectbox("ë¶„ì„í•  ì§ë¬´ ì„ íƒ", sorted(skills_df["ì§ë¬´"].unique()), key="skill_job")
        filtered_skills = skills_df[skills_df["ì§ë¬´"] == job_to_show]
        fig_skills_market = px.bar(filtered_skills.sort_values("ë¹ˆë„"), x="ë¹ˆë„", y="ê¸°ìˆ ìŠ¤íƒ", title=f"'{job_to_show}' ì§ë¬´ ì£¼ìš” ê¸°ìˆ ìŠ¤íƒ", orientation='h')
        st.plotly_chart(fig_skills_market, use_container_width=True)
    with market_tabs[2]:
        st.markdown("#### **ğŸ“ˆ ì§ë¬´ë³„ ê³µê³  ê²½ë ¥ë ˆë²¨ ë¶„í¬**")
        c1, c2 = st.columns(2)
        with c1:
            fig_levels = px.bar(levels_df, x="jobLevels", y="ê³µê³ ìˆ˜", color="ì§ë¬´", title="ì „ì²´ ì§ë¬´ë³„ ê²½ë ¥ ë¶„í¬", category_orders={"jobLevels": ["JUNIOR", "MIDDLE", "SENIOR"]}, labels={"jobLevels": "ê²½ë ¥ ìˆ˜ì¤€", "ê³µê³ ìˆ˜": "ì±„ìš© ê³µê³  ìˆ˜"})
            st.plotly_chart(fig_levels, use_container_width=True)
        with c2:
            st.markdown("#### **ğŸ¯ íŠ¹ì • ì§ë¬´ ê²½ë ¥ ë¶„í¬**")
            selected_pie_job = st.selectbox("ì§ë¬´ ì„ íƒ", sorted(levels_df["ì§ë¬´"].unique()), key="pie_job")
            single_job_levels = levels_df[levels_df['ì§ë¬´'] == selected_pie_job]
            if not single_job_levels.empty:
                fig_pie = px.pie(single_job_levels, names='jobLevels', values='ê³µê³ ìˆ˜', title=f"'{selected_pie_job}' ì§ë¬´ ê²½ë ¥ ë¶„í¬", hole=0.3)
                fig_pie.update_traces(textinfo='percent+label')
                st.plotly_chart(fig_pie, use_container_width=True)
            else:
                st.info(f"'{selected_pie_job}' ì§ë¬´ì— ëŒ€í•œ ê²½ë ¥ ë¶„í¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- 8. AI ë„ìš°ë¯¸ íƒ­ ---
with main_tabs[2]:
    st.subheader("Groq ê¸°ë°˜ ì´ˆê³ ì† AI ë¶„ì„")
    if client is None:
        st.error("AI ë„ìš°ë¯¸ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Groq API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.", icon="ğŸ”‘")
    else:
        ai_feature_tabs = st.tabs(["**ğŸ¤– AI ë§ì¶¤ ì§ë¬´ ì¶”ì²œ**", "**ğŸ“„ AI ì±„ìš©ê³µê³  ë¶„ì„**", "**ğŸ’¬ AI ì»¤ë¦¬ì–´ ìƒë‹´**"])

        with ai_feature_tabs[0]:
            st.markdown("##### ë‚˜ì˜ í”„ë¡œí•„ê³¼ ì‹œì¥ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ AIê°€ ì§ë¬´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")
            user_profile_summary = f"í˜„ì¬ **'{interest_job}'** ì§ë¬´ì— ê´€ì‹¬ì´ ìˆê³ , í¬ë§ ê²½ë ¥ì€ **'{career_level}'**ì…ë‹ˆë‹¤. ì €ì˜ ì„±í–¥ì€ **'{work_style}'**í•˜ë©°, **'{work_env}'** í™˜ê²½ì„ ì„ í˜¸í•©ë‹ˆë‹¤."
            st.info(f"**ë¶„ì„ ê¸°ì¤€ í”„ë¡œí•„:** {user_profile_summary}")
            if st.button("AIì—ê²Œ ë§ì¶¤ ì§ë¬´ ì¶”ì²œë°›ê¸°", type="primary"):
                with st.spinner("AIê°€ ë‹¹ì‹ ì˜ í”„ë¡œí•„ê³¼ ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§ì¶¤ ì§ë¬´ë¥¼ ì¶”ì²œ ì¤‘ì…ë‹ˆë‹¤..."):
                    market_context = prepare_ai_analysis_data(skills_df, levels_df, rallit_df, interest_job, career_level)
                    system_prompt = "You are a highly-skilled Korean career consultant. Your primary mission is to provide insightful and empathetic career advice to users, and all your responses must be in Korean."
                    user_prompt = f"**[ì‚¬ìš©ì í”„ë¡œí•„]**\n{user_profile_summary}\n\n**[ì°¸ê³ ìš© ì‹œì¥ ë°ì´í„°]**\n{market_context}\n\n**[ìˆ˜í–‰í•  ì‘ì—…]**\në‹¹ì‹ ì€ ìµœê³ ì˜ ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ìœ„ì˜ ëª¨ë“  ì •ë³´(ì‚¬ìš©ì í”„ë¡œí•„, ì‹œì¥ ë°ì´í„°)ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ì•„ë˜ì˜ ì‘ì—…ì„ **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ** ìˆ˜í–‰í•´ì£¼ì„¸ìš”.\n\n1.  **ìµœì  ì§ë¬´ ì¶”ì²œ (Top 3)**: ì´ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì˜ ë§ëŠ” ì§ë¬´ 3ê°€ì§€ë¥¼ ì¶”ì²œí•˜ê³ , ê° ì§ë¬´ëª… ì•ì—ëŠ” ğŸ¥‡, ğŸ¥ˆ, ğŸ¥‰ ì´ëª¨ì§€ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”.\n2.  **ì¶”ì²œ ê·¼ê±°**: ê° ì§ë¬´ì— ëŒ€í•´, ì‚¬ìš©ìì˜ í”„ë¡œí•„(ì„±í–¥, ê´€ì‹¬ì‚¬ ë“±)ê³¼ ì‹œì¥ ë°ì´í„°(ê¸°ìˆ ìŠ¤íƒ, ê²½ë ¥ë¶„í¬ ë“±)ë¥¼ ì—°ê²°í•˜ì—¬ **ì™œ** ì´ ì§ë¬´ê°€ ì í•©í•œì§€ì— ëŒ€í•œ ìƒì„¸í•œ ê·¼ê±°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n3.  **ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ**: ê° ì§ë¬´ì— ëŒ€í•´, ì‚¬ìš©ìê°€ ì§€ê¸ˆ ë‹¹ì¥ ì‹œì‘í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë‹¤ìŒ ë‹¨ê³„(í•™ìŠµ, í”„ë¡œì íŠ¸ ë“±)ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.\n4.  **ì¢…í•© ì¡°ì–¸**: ë§ˆì§€ë§‰ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ì„±ê³µì ì¸ ì»¤ë¦¬ì–´ë¥¼ ìœ„í•œ ë”°ëœ»í•œ ì¢…í•© ì¡°ì–¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.\n\n**[ì¶œë ¥ í˜•ì‹]**\n- ì „ì²´ ë‹µë³€ì€ ëª…í™•í•˜ê³  ì¹œì ˆí•œ ì–´ì¡°ì˜ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n- ê° ì¶”ì²œ ì§ë¬´ëŠ” `### ğŸ¥‡ 1. [ì§ë¬´ëª…]` ê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”."
                    chat_completion = client.chat.completions.create(messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], model=selected_model, temperature=temperature, max_tokens=max_tokens)
                    st.session_state.ai_recommendation_result = chat_completion.choices[0].message.content
            if "ai_recommendation_result" in st.session_state:
                st.markdown("---"); st.subheader("ğŸ¤– AI ë§ì¶¤ ì¶”ì²œ ê²°ê³¼"); st.markdown(st.session_state.ai_recommendation_result)

        with ai_feature_tabs[1]:
            st.markdown("##### ì±„ìš© ê³µê³ ë¥¼ ì…ë ¥í•˜ë©´ AIê°€ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤.")
            job_desc_input = st.text_area("ì—¬ê¸°ì— ì±„ìš© ê³µê³ ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:", height=250, key="jd_input")
            if st.button("ë¶„ì„ ì‹œì‘í•˜ê¸°", key="analyze_jd"):
                if job_desc_input:
                    with st.spinner("Groq AIê°€ ì±„ìš© ê³µê³ ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        system_prompt = "You are a professional HR analyst who provides structured summaries. All your responses must be in Korean."
                        user_prompt = f"ì•„ë˜ ì±„ìš©ê³µê³ ë¥¼ ë¶„ì„í•´ì„œ, ì§€ì •ëœ í˜•ì‹ì— ë§ì¶° **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ** ìš”ì•½í•´ì¤˜.\n\n**[ì±„ìš©ê³µê³  ì›ë¬¸]**\n---\n{job_desc_input}\n---\n\n**[ì¶œë ¥ í˜•ì‹]**\n### ğŸ“ í•µì‹¬ ìš”ì•½ (3ê°€ì§€)\n- [í•µì‹¬ ì—­í•  ë° ì±…ì„ 1]\n- [í•µì‹¬ ì—­í•  ë° ì±…ì„ 2]\n- [í•µì‹¬ ì—­í•  ë° ì±…ì„ 3]\n\n### ğŸ› ï¸ ìš”êµ¬ ê¸°ìˆ  ìŠ¤íƒ\n- [ê¸°ìˆ  1], [ê¸°ìˆ  2], ...\n\n### ğŸ“ˆ ì˜ˆìƒ ê²½ë ¥ ìˆ˜ì¤€\n- [ì˜ˆ: ì‹ ì…, 1~3ë…„ì°¨, 5ë…„ ì´ìƒ ë“±]\n\n### ğŸ—£ï¸ ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸ (3ê°€ì§€)\n1. [ê¸°ìˆ  ë˜ëŠ” ê²½í—˜ ê´€ë ¨ ì§ˆë¬¸ 1]\n2. [ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ ê´€ë ¨ ì§ˆë¬¸ 2]\n3. [ì¡°ì§ ë¬¸í™” ì í•©ì„± ê´€ë ¨ ì§ˆë¬¸ 3]"
                        chat_completion = client.chat.completions.create(messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], model=selected_model, temperature=temperature, max_tokens=max_tokens)
                        st.session_state.jd_analysis_result = chat_completion.choices[0].message.content
                else: st.warning("ë¶„ì„í•  ì±„ìš© ê³µê³ ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            if "jd_analysis_result" in st.session_state:
                st.markdown("---"); st.subheader("ğŸ¤– AI ë¶„ì„ ê²°ê³¼"); st.markdown(st.session_state.jd_analysis_result)

        with ai_feature_tabs[2]:
            st.markdown("##### í˜„ì¬ ë‚˜ì˜ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ì»¤ë¦¬ì–´ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
            if "ai_chat_messages" not in st.session_state:
                st.session_state.ai_chat_messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ì»¤ë¦¬ì–´ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}]
            for message in st.session_state.ai_chat_messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            user_profile_for_chat = f"ì €ì˜ í”„ë¡œí•„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: í˜„ì¬ '{interest_job}' ì§ë¬´ì— ê´€ì‹¬ì´ ìˆê³ , í¬ë§ ê²½ë ¥ì€ '{career_level}'ì…ë‹ˆë‹¤. ì €ì˜ ì„±í–¥ì€ '{work_style}'í•˜ë©°, '{work_env}' í™˜ê²½ì„ ì„ í˜¸í•©ë‹ˆë‹¤."
            if user_question := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
                st.session_state.ai_chat_messages.append({"role": "user", "content": user_question})
                with st.chat_message("user"): st.markdown(user_question)
                with st.chat_message("assistant"):
                    with st.spinner("AIê°€ ë‹µë³€ì„ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
                        system_prompt = "You are a friendly and insightful career counselor. Your primary language for all responses is Korean."
                        messages_for_api = [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": f"{user_profile_for_chat}\n\nì§ˆë¬¸: {user_question}"}
                        ]
                        chat_completion = client.chat.completions.create(messages=messages_for_api, model=selected_model, temperature=temperature, max_tokens=max_tokens)
                        response = chat_completion.choices[0].message.content
                        st.markdown(response)
                st.session_state.ai_chat_messages.append({"role": "assistant", "content": response})

# 9. í‘¸í„°
st.markdown("---")
st.markdown('<div style="text-align: center; color: #666;"><p>ğŸ§  Job-Fit Insight Dashboard | Powered by Streamlit & Groq</p></div>', unsafe_allow_html=True)

import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
from pathlib import Path
import glob
from wordcloud import WordCloud # --- [ê³ ë„í™”] ì›Œë“œ í´ë¼ìš°ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
import matplotlib.pyplot as plt

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="Job-Fit Insight Dashboard", page_icon="ğŸ§ ", layout="wide", initial_sidebar_state="expanded")

# --- 2. CSS ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .main-header { background: linear-gradient(90deg, #1f4e79 0%, #2980b9 100%); padding: 1.5rem; border-radius: 10px; color: white; margin-bottom: 2rem; }
    .highlight-card { background: white; padding: 1.5rem; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); border-left: 5px solid #ff6b35; }
    .job-posting-card { background: #ffffff; padding: 1rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 1rem; border: 1px solid #e9ecef; }
    .job-posting-card a { text-decoration: none; color: #1f4e79; font-weight: bold; font-size: 1.1em; }
    .job-posting-card p { margin: 0.3rem 0; color: #495057; font-size: 0.9em; }
    div[data-testid="metric-container"] { background-color: #f8f9fa; border-left: 5px solid #2980b9; padding: 1rem; border-radius: 10px; }
</style>
""", unsafe_allow_html=True)

# --- 3. ë°ì´í„° ë¡œë”© (ì´ì „ê³¼ ë™ì¼) ---
@st.cache_resource
def init_connection(db_path="data/job_fit_insight.db"):
    db_file = Path(db_path)
    if not db_file.exists(): st.error(f"DB íŒŒì¼('{db_path}') ì—†ìŒ. `setup_database.py` ì‹¤í–‰ í•„ìš”."); st.stop()
    return sqlite3.connect(db_file, check_same_thread=False)

def generate_sample_youth_data():
    data = {'ì„±ë³„': ['ë‚¨ì„±', 'ì—¬ì„±', 'ë‚¨ì„±', 'ì—¬ì„±'], 'ì—°ë ¹ê³„ì¸µë³„': ['15-29ì„¸', '15-29ì„¸', '30-39ì„¸', '30-39ì„¸'], '2025.03_ì‹¤ì—…ë¥ ': [6.8, 6.1, 3.1, 3.5], '2025.03_ê²½ì œí™œë™ì¸êµ¬': [2450000, 2150000, 3400000, 3100000], '2025.03_ì·¨ì—…ì': [2283000, 2018000, 3295000, 2990000], '2025.04_ì‹¤ì—…ë¥ ': [7.0, 6.3, 3.2, 3.6], '2025.04_ê²½ì œí™œë™ì¸êµ¬': [2460000, 2160000, 3420000, 3120000], '2025.04_ì·¨ì—…ì': [2287000, 2023000, 3310000, 3010000], '2025.05_ì‹¤ì—…ë¥ ': [6.9, 6.2, 3.0, 3.4], '2025.05_ê²½ì œí™œë™ì¸êµ¬': [2470000, 2170000, 3430000, 3130000], '2025.05_ì·¨ì—…ì': [2299000, 2035000, 3325000, 3020000]}
    return pd.DataFrame(data)

@st.cache_data
def load_data(_conn):
    skills_df = pd.read_sql("SELECT * FROM top10_skills_per_job", _conn)
    levels_df = pd.read_sql("SELECT * FROM joblevel_counts", _conn)
    rallit_df = None
    try:
        csv_files = glob.glob(str(Path("data") / "rallit_*.csv"))
        if csv_files: rallit_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True).drop_duplicates(subset=['url']).reset_index(drop=True)
    except Exception as e: print(f"Error loading Rallit CSVs: {e}")
    try: youth_df = pd.read_sql("SELECT * FROM youth_summary", _conn)
    except pd.io.sql.DatabaseError: youth_df = generate_sample_youth_data()
    overall_data = youth_df.groupby('ì—°ë ¹ê³„ì¸µë³„', as_index=False).sum(numeric_only=True)
    overall_data["ì„±ë³„"] = "ì „ì²´"
    rate_cols = [col for col in youth_df.columns if "_ì‹¤ì—…ë¥ " in col]
    mean_rates = youth_df.groupby('ì—°ë ¹ê³„ì¸µë³„')[rate_cols].mean().reset_index()
    for col in rate_cols: overall_data[col] = overall_data['ì—°ë ¹ê³„ì¸µë³„'].map(mean_rates.set_index('ì—°ë ¹ê³„ì¸µë³„')[col])
    youth_df = pd.concat([youth_df, overall_data], ignore_index=True)
    id_vars = ["ì„±ë³„", "ì—°ë ¹ê³„ì¸µë³„"]
    unemp_long = youth_df.melt(id_vars=id_vars, value_vars=rate_cols, var_name="ì›”", value_name="ì‹¤ì—…ë¥ ")
    pop_long = youth_df.melt(id_vars=id_vars, value_vars=[c for c in youth_df.columns if "_ê²½ì œí™œë™ì¸êµ¬" in c], var_name="ì›”", value_name="ê²½ì œí™œë™ì¸êµ¬")
    emp_long = youth_df.melt(id_vars=id_vars, value_vars=[c for c in youth_df.columns if "_ì·¨ì—…ì" in c], var_name="ì›”", value_name="ì·¨ì—…ì")
    unemp_long["ì›”"], pop_long["ì›”"], emp_long["ì›”"] = [df["ì›”"].str.replace(s, "") for df, s in [(unemp_long, "_ì‹¤ì—…ë¥ "), (pop_long, "_ê²½ì œí™œë™ì¸êµ¬"), (emp_long, "_ì·¨ì—…ì")]]
    trend_df = unemp_long.merge(pop_long, on=id_vars+["ì›”"]).merge(emp_long, on=id_vars+["ì›”"])
    trend_df["ì›”"] = pd.to_datetime(trend_df["ì›”"], format="%Y.%m").dt.strftime("%Y.%m")
    trend_df = trend_df.sort_values("ì›”")
    return trend_df, skills_df, levels_df, rallit_df

conn = init_connection()
trend_df, skills_df, levels_df, rallit_df = load_data(conn)


# --- [ê³ ë„í™”] ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± í•¨ìˆ˜ ---
@st.cache_data
def create_word_cloud(df):
    """ê¸°ìˆ ìŠ¤íƒ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ê¸°ìˆ ìŠ¤íƒê³¼ ë¹ˆë„ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    d = dict(zip(df['ê¸°ìˆ ìŠ¤íƒ'], df['ë¹ˆë„']))
    wc = WordCloud(
        font_path='malgun', # í•œê¸€ í°íŠ¸ ê²½ë¡œ (Windows ê¸°ì¤€)
        background_color='white',
        width=400,
        height=300,
        colormap='viridis'
    ).generate_from_frequencies(d)
    return wc

# --- 4. ë¶„ì„ ë¡œì§ ë° 5. ì‚¬ì´ë“œë°” UI (ì´ì „ê³¼ ë™ì¼) ---
job_category_map = { "ë°ì´í„° ë¶„ì„": ["ë°ì´í„°", "ë¶„ì„", "Data", "BI"], "ë§ˆì¼€íŒ…": ["ë§ˆì¼€íŒ…", "ë§ˆì¼€í„°", "Marketing", "ê´‘ê³ ", "ì½˜í…ì¸ "], "ê¸°íš": ["ê¸°íš", "PM", "PO", "ì„œë¹„ìŠ¤", "Product"], "í”„ë¡ íŠ¸ì—”ë“œ": ["í”„ë¡ íŠ¸ì—”ë“œ", "Frontend", "React", "Vue", "ì›¹ ê°œë°œ"], "ë°±ì—”ë“œ": ["ë°±ì—”ë“œ", "Backend", "Java", "Python", "ì„œë²„", "Node.js"], "AI/ML": ["AI", "ML", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ì¸ê³µì§€ëŠ¥"], "ë””ìì¸": ["ë””ìì¸", "ë””ìì´ë„ˆ", "Designer", "UI", "UX", "BX", "ê·¸ë˜í”½"], "ì˜ì—…": ["ì˜ì—…", "Sales", "ì„¸ì¼ì¦ˆ", "ë¹„ì¦ˆë‹ˆìŠ¤", "Business Development"], "ê³ ê°ì§€ì›": ["CS", "CX", "ê³ ê°", "ì§€ì›", "ì„œë¹„ìŠ¤ ìš´ì˜"], "ì¸ì‚¬": ["ì¸ì‚¬", "HR", "ì±„ìš©", "ì¡°ì§ë¬¸í™”", "Recruiting"] }
def calculate_job_fit(work_style, work_env, interest_job):
    job_fit_scores = {}
    for job in job_category_map.keys():
        score = 0
        if "ë¶„ì„" in work_style and any(k in job for k in ["ë°ì´í„°", "AI/ML", "ë°±ì—”ë“œ"]): score += 50
        elif "ì°½ì˜" in work_style and any(k in job for k in ["ë§ˆì¼€íŒ…", "ë””ìì¸", "ê¸°íš"]): score += 50
        if "ë…ë¦½" in work_env and any(k in job for k in ["ì—”ë“œ", "ë¶„ì„", "AI/ML"]): score += 40
        elif "íŒ€ì›Œí¬" in work_env and any(k in job for k in ["ê¸°íš", "ë§ˆì¼€íŒ…", "ë””ìì¸"]): score += 40
        if job == interest_job: score += 15
        job_fit_scores[job] = min(100, score + 5)
    return job_fit_scores

with st.sidebar:
    with st.container(border=True):
        st.header("ğŸ‘¤ ë‚˜ì˜ í”„ë¡œí•„ ì„¤ì •")
        job_options = sorted(list(job_category_map.keys()))
        interest_job = st.selectbox("ê´€ì‹¬ ì§ë¬´", job_options, key="interest_job")
        career_options = ["ìƒê´€ ì—†ìŒ", "ì‹ ì…", "1-3ë…„", "4-6ë…„", "7-10ë…„ ì´ìƒ"]
        career_level = st.selectbox("í¬ë§ ê²½ë ¥ ìˆ˜ì¤€", career_options, key="career_level")
    st.write("")
    with st.container(border=True):
        st.header("ğŸ§  ë‚˜ì˜ ì„±í–¥ ì§„ë‹¨")
        work_style = st.radio("ì„ í˜¸í•˜ëŠ” ì—…ë¬´ ìŠ¤íƒ€ì¼ì€?", ["ë¶„ì„ì ì´ê³  ë…¼ë¦¬ì ", "ì°½ì˜ì ì´ê³  í˜ì‹ ì ", "ì²´ê³„ì ì´ê³  ê³„íšì ", "ì‚¬êµì ì´ê³  í˜‘ë ¥ì "], key="work_style")
        work_env = st.radio("ì„ í˜¸í•˜ëŠ” ì—…ë¬´ í™˜ê²½ì€?", ["ë…ë¦½ì ìœ¼ë¡œ ì¼í•˜ê¸°", "íŒ€ì›Œí¬ ì¤‘ì‹¬", "ë¹ ë¥¸ ë³€í™”ì™€ ë„ì „", "ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ"], key="work_env")

# 6. ë©”ì¸ ë¡œì§ ì‹¤í–‰
job_fit_scores = calculate_job_fit(work_style, work_env, interest_job)
score_df = pd.DataFrame(job_fit_scores.items(), columns=["ì§ë¬´", "ì í•©ë„"]).sort_values("ì í•©ë„", ascending=False).reset_index(drop=True)
top_job = score_df.iloc[0]["ì§ë¬´"] if not score_df.empty else "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

# 7. ëŒ€ì‹œë³´ë“œ ë³¸ë¬¸
st.markdown('<div class="main-header"><h1>ğŸ§  Job-Fit Insight Dashboard</h1><p>ë‚˜ì˜ ì„±í–¥ê³¼ ì‹œì¥ ë°ì´í„°ë¥¼ ê²°í•©í•œ ìµœì ì˜ ì»¤ë¦¬ì–´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.</p></div>', unsafe_allow_html=True)

if 'active_tab' not in st.session_state:
    st.session_state.active_tab = "ğŸš€ ë‚˜ì˜ ë§ì¶¤ ë¶„ì„"

main_tabs = st.tabs(["ğŸš€ ë‚˜ì˜ ë§ì¶¤ ë¶„ì„", "ğŸ“Š ì‹œì¥ ë™í–¥ ë¶„ì„"])

# ë§ì¶¤ ë¶„ì„ íƒ­
with main_tabs[0]:
    st.subheader(f"ì‚¬ìš©ìë‹˜ì„ ìœ„í•œ ë§ì¶¤ ì§ë¬´ ë¶„ì„")
    col1, col2 = st.columns([0.5, 0.5])
    with col1:
        st.markdown('<div class="highlight-card" style="height: 100%;">', unsafe_allow_html=True)
        st.markdown(f"<h4>ğŸ† ìµœì  ì¶”ì²œ ì§ë¬´</h4><h1>{top_job}</h1>", unsafe_allow_html=True)
        progress_value = score_df.iloc[0]["ì í•©ë„"]
        st.progress(int(progress_value) / 100)
        st.markdown(f"**ì í•©ë„: {progress_value}%**")
        st.markdown(f"ğŸ‘‰ **'{work_style}'** ì„±í–¥ê³¼ **'{work_env}'** í™˜ê²½ì„ ì„ í˜¸í•˜ëŠ” ë‹¹ì‹ ì—ê²ŒëŠ” **'{top_job}'** ì§ë¬´ê°€ ê°€ì¥ ì˜ ë§ì•„ìš”!")
        st.markdown('</div>', unsafe_allow_html=True)
    with col2:
        # --- [ê³ ë„í™”] ìŠ¤í‚¬ ì •ë³´ í‘œì‹œ ë¡œì§ ì „ì²´ ìˆ˜ì • ---
        skills_to_show = skills_df[skills_df["ì§ë¬´"] == top_job]
        fallback_used = False
        if skills_to_show.empty:
            skills_to_show = skills_df[skills_df["ì§ë¬´"] == interest_job]
            fallback_used = True

        if not skills_to_show.empty:
            if fallback_used:
                st.info(f"'{top_job}'ì˜ ìŠ¤í‚¬ ì •ë³´ê°€ ì—†ì–´, ê´€ì‹¬ ì§ë¬´ **'{interest_job}'**ì˜ ì •ë³´ë¥¼ ëŒ€ì‹  í‘œì‹œí•©ë‹ˆë‹¤.")
            
            # ì›Œë“œ í´ë¼ìš°ë“œì™€ ë°” ì°¨íŠ¸ë¥¼ íƒ­ìœ¼ë¡œ ì œê³µ
            skill_tabs = st.tabs(["ğŸ“Š ê¸°ìˆ  ìŠ¤íƒ ë¹ˆë„", "â˜ï¸ ì›Œë“œ í´ë¼ìš°ë“œ"])
            with skill_tabs[0]:
                fig_skill = px.bar(skills_to_show.sort_values("ë¹ˆë„", ascending=True), x="ë¹ˆë„", y="ê¸°ìˆ ìŠ¤íƒ", orientation='h', title=f"'{interest_job if fallback_used else top_job}' í•µì‹¬ ê¸°ìˆ ")
                fig_skill.update_layout(yaxis_title="")
                st.plotly_chart(fig_skill, use_container_width=True)
            with skill_tabs[1]:
                try:
                    wc = create_word_cloud(skills_to_show)
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.imshow(wc, interpolation='bilinear')
                    ax.axis('off')
                    st.pyplot(fig)
                except Exception as e:
                    st.error("ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í•œê¸€ í°íŠ¸ ì„¤ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    print(e)
        else:
            # --- [ê³ ë„í™”] ì •ë³´ ë¶€ì¬ ì‹œ í–‰ë™ ìœ ë„ UI ---
            st.markdown('<div class="highlight-card" style="height: 100%; text-align: center;">', unsafe_allow_html=True)
            st.warning(f"'{top_job}' ì§ë¬´ì˜ ìƒì„¸ ìŠ¤í‚¬ ì •ë³´ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.write("ë‹¤ë¥¸ ì§ë¬´ì˜ ê¸°ìˆ  íŠ¸ë Œë“œê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
            if st.button("ğŸ“ˆ ì‹œì¥ ë™í–¥ íƒ­ì—ì„œ ê¸°ìˆ  ìŠ¤íƒ íƒìƒ‰í•˜ê¸°"):
                 # ì´ ë²„íŠ¼ì€ ì•„ì§ Streamlitì—ì„œ íƒ­ ì „í™˜ì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šì•„, UXì  ì•ˆë‚´ ì—­í• 
                 st.success("ìƒë‹¨ì˜ 'ì‹œì¥ ë™í–¥ ë¶„ì„' íƒ­ì„ í´ë¦­í•˜ì—¬ 'ê¸°ìˆ  ìŠ¤íƒ'ì„ í™•ì¸í•´ë³´ì„¸ìš”!")
            st.markdown('</div>', unsafe_allow_html=True)
            
    st.markdown("---")
    st.subheader("ğŸ“Œ ë‚˜ì—ê²Œ ë§ëŠ” Rallit ì±„ìš©ê³µê³ ")
    if rallit_df is not None:
        # ... (ì´ì „ê³¼ ë™ì¼)
        # ...
        pass # ì´í•˜ ìƒëµ (ì´ì „ ì½”ë“œì™€ ë™ì¼)

# ì‹œì¥ ë™í–¥ ë¶„ì„ íƒ­ (ì´ì „ê³¼ ë™ì¼)
with main_tabs[1]:
    # ... (ì´ì „ê³¼ ë™ì¼)
    # ...
    pass # ì´í•˜ ìƒëµ (ì´ì „ ì½”ë“œì™€ ë™ì¼)

# --- 8. í‘¸í„° ---
st.markdown("---")
st.markdown('<div style="text-align: center; color: #666;"><p>ğŸ§  Job-Fit Insight Dashboard | Powered by Streamlit</p></div>', unsafe_allow_html=True)
